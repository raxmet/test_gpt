{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/raxmet/test_gpt/blob/main/Gpt_2_rus_pub.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK4QnVr_q_qL"
      },
      "source": [
        "В принципе можно сразу нажать ***Ctrl-F9***, дождаться сообщения **Введите текст >>>** и начать эксперименты с Русской GPT-2. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJyCPMIM3w8T"
      },
      "source": [
        "# Клонируем репозиторий... \n",
        "!git clone https://github.com/Nehc/gpt-2.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNtUZjRT8BQj"
      },
      "source": [
        "%cd gpt-2\n",
        "\n",
        "# Зависимости и библиотеки... \n",
        "\n",
        "!pip3 install -r requirements.txt\n",
        "\n",
        "!pip3 install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xewtqri-8tCi"
      },
      "source": [
        "# Use Tensorflow 1\n",
        "%tensorflow_version 1.x\n",
        "\n",
        "# Select GPT-2 model: 117M, 124M, 355M, 774M, 1558M\n",
        "\n",
        "model_name = '1250M'     # '1250М' - наша натренированная. На текущий момент в реале только она и доступна"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvnTe4o2mLH3"
      },
      "source": [
        "# Тащим модель с дружественного хостинга... Придется подождать.  \n",
        "!python3 download_model.py $model_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFnRRF49psMe"
      },
      "source": [
        "**В исходный скрипт были внесены некоторые изменения: **\n",
        "\n",
        "После первого ввода ситема выдаст очень короткий текст (5 токенов, что иногда буквально пара слов). Если вы хотите большего - просто жмите ENTER: на вход системы будет передана вся история + последний вывод.\n",
        "\n",
        "Если вам не нравится, что происходит - вы можете набрать ***new*** и или просто начать совсем заново, или взять прошлый вывод до того, как GPT свернула не туда...\n",
        "\n",
        "Жми (>) В следующем блоке!  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PB1gYfkeZvU"
      },
      "source": [
        "# Generate samples by user input. Wait for string \"Model prompt >>>\", enter you text (begin phrase for network) and press Enter\n",
        "\n",
        "!python3 src/interactive_conditional_samples.py --model_name=$model_name"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}